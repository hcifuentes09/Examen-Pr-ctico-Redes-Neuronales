{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93b6e444",
   "metadata": {},
   "source": [
    "# Examen Práctico – Redes Neuronales  \n",
    "## Implementación de un Perceptrón para Regresión  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a3540f",
   "metadata": {},
   "source": [
    "En este notebook se desarrolla paso a paso la implementación de un perceptrón simple para un problema de regresión, utilizando el conjunto de datos **California Housing**.\n",
    "\n",
    "El objetivo es conectar de manera explícita la teoría presentada en el libro (conceptos como vector de características, pesos, sesgo, suma ponderada y\n",
    "función de pérdida) con una implementación práctica en Python, empleando principalmente **NumPy** y herramientas básicas de **scikit-learn** para la\n",
    "carga y normalización de los datos.\n",
    "\n",
    "El notebook funciona como un cuaderno de trabajo experimental, donde se implementan y prueban los distintos componentes del modelo, mientras que las\n",
    "justificaciones teóricas detalladas se presentan por separado en el documento `respuestas_teoricas.md`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1816c323",
   "metadata": {},
   "source": [
    "En esta sección se carga el conjunto de datos California Housing utilizando\n",
    "`fetch_california_housing` de sklearn. Se extraen las características de entrada\n",
    "y la variable objetivo, y se imprime una descripción general del dataset para\n",
    "entender su estructura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f371de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descripción del dataset:\n",
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 20640\n",
      "\n",
      ":Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      ":Attribute Information:\n",
      "    - MedInc        median income in block group\n",
      "    - HouseAge      median house age in block group\n",
      "    - AveRooms      average number of rooms per household\n",
      "    - AveBedrms     average number of bedrooms per household\n",
      "    - Population    block group population\n",
      "    - AveOccup      average number of household members\n",
      "    - Latitude      block group latitude\n",
      "    - Longitude     block group longitude\n",
      "\n",
      ":Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
      "\n",
      "The target variable is the median house value for California districts,\n",
      "expressed in hundreds of thousands of dollars ($100,000).\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "A household is a group of people residing within a home. Since the average\n",
      "number of rooms and bedrooms in this dataset are provided per household, these\n",
      "columns may take surprisingly large values for block groups with few households\n",
      "and many empty houses, such as vacation resorts.\n",
      "\n",
      "It can be downloaded/loaded\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Cargar el dataset\n",
    "california = fetch_california_housing()\n",
    "X = california.data\n",
    "y = california.target\n",
    "feature_names = california.feature_names\n",
    "\n",
    "print('Descripción del dataset:')\n",
    "print(california.DESCR[:1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717617d5",
   "metadata": {},
   "source": [
    "El conjunto de datos se divide en subconjuntos de entrenamiento y prueba.\n",
    "Posteriormente, las características se normalizan usando `StandardScaler`\n",
    "para garantizar una escala uniforme, lo cual es importante para el entrenamiento\n",
    "estable del perceptrón."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8ef3624f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled shape: (16512, 8)\n"
     ]
    }
   ],
   "source": [
    "# División en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Normalización\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"X_train_scaled shape:\", X_train_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd767c8b",
   "metadata": {},
   "source": [
    "Se inicializan los parámetros del perceptrón: el vector de pesos `w` y el sesgo `b`.\n",
    "Los pesos se inicializan con valores aleatorios pequeños y el sesgo en cero,\n",
    "siguiendo las recomendaciones teóricas del modelo del perceptrón."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7be0911d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def inicializar_parametros(n_caracteristicas):\n",
    "    '''\n",
    "    Inicializa los pesos y el sesgo del perceptrón.\n",
    "    '''\n",
    "    w = np.random.randn(n_caracteristicas, 1) * 0.01\n",
    "    b = 0.0\n",
    "    return w, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "56b7b26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de w: (8, 1)\n",
      "Sesgo b: 0.0\n"
     ]
    }
   ],
   "source": [
    "w, b = inicializar_parametros(X_train_scaled.shape[1])\n",
    "print(\"Forma de w:\", w.shape)\n",
    "print(\"Sesgo b:\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f64939",
   "metadata": {},
   "source": [
    "### Propagación hacia adelante (suma ponderada)\n",
    "\n",
    "En esta sección se implementa la propagación hacia adelante del perceptrón.\n",
    "Siguiendo el Capítulo 2 del material del curso, se calcula la suma ponderada:\n",
    "\n",
    "\\[\n",
    "z = X \\mathbf{w} + b\n",
    "\\]\n",
    "\n",
    "donde \\(X\\) es la matriz de características, \\(\\mathbf{w}\\) el vector de pesos y \\(b\\) el sesgo.\n",
    "En un problema de regresión, esta salida corresponde directamente a la predicción del modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "de934d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagacion_adelante(X, w, b):\n",
    "    '''\n",
    "    Calcula la suma ponderada para todas las observaciones.\n",
    "    '''\n",
    "    y_pred = X @ w + b\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6113fea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones iniciales:\n",
      "[-0.02219977 -0.00341057  0.00708927 -0.01912173  0.00092429]\n",
      "\n",
      "Valores reales:\n",
      "[1.03  3.821 1.726 0.934 0.965]\n"
     ]
    }
   ],
   "source": [
    "# Predicciones iniciales para los primeros 5 ejemplos\n",
    "y_pred_5 = propagacion_adelante(X_train_scaled[:5], w, b)\n",
    "\n",
    "print(\"Predicciones iniciales:\")\n",
    "print(y_pred_5.flatten())\n",
    "\n",
    "print(\"\\nValores reales:\")\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105f28cf",
   "metadata": {},
   "source": [
    "Las predicciones iniciales no son precisas, ya que el modelo aún no ha sido entrenado.\n",
    "Los pesos se inicializaron con valores aleatorios pequeños, por lo que la salida inicial\n",
    "del modelo es cercana a cero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5f6c55",
   "metadata": {},
   "source": [
    "### Función de pérdida: Error Cuadrático Medio (MSE)\n",
    "\n",
    "En problemas de regresión, la calidad de las predicciones se evalúa mediante una función de pérdida.\n",
    "En este trabajo se utiliza el **Error Cuadrático Medio (MSE)**, que mide el promedio del cuadrado de las diferencias entre las predicciones del modelo y los valores reales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9e5f56a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_perdida(y_pred, y_real):\n",
    "    '''\n",
    "    Calcula el error cuadrático medio (MSE).\n",
    "\n",
    "    MSE = (1/m) * sum((y_pred - y_real)^2)\n",
    "    '''\n",
    "    m = y_real.shape[0]\n",
    "    mse = (1 / m) * np.sum((y_pred - y_real) ** 2)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa6f7ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(5.61312792620843)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcular predicciones iniciales\n",
    "y_pred_inicial = propagacion_adelante(X_train_scaled, w, b)\n",
    "\n",
    "# Calcular pérdida inicial\n",
    "perdida_inicial = calcular_perdida(y_pred_inicial, y_train.reshape(-1, 1))\n",
    "\n",
    "perdida_inicial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3623c4",
   "metadata": {},
   "source": [
    "## Cálculo de gradientes\n",
    "\n",
    "En esta sección se implementa el cálculo de los gradientes de la función de pérdida\n",
    "(MSE) respecto a los pesos \\(w\\) y al sesgo \\(b\\), siguiendo las expresiones\n",
    "derivadas en la Parte III del reporte teórico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bb6a54a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de y_pred: (16512, 1)\n"
     ]
    }
   ],
   "source": [
    "# Propagación hacia adelante\n",
    "y_pred = propagacion_adelante(X_train_scaled, w, b)\n",
    "\n",
    "print(\"Forma de y_pred:\", y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f95ed3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_gradientes(X, y_pred, y_real):\n",
    "    '''\n",
    "    Calcula los gradientes de la pérdida respecto a w y b.\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    X : numpy array de forma (m, n)\n",
    "    y_pred : numpy array de forma (m, 1)\n",
    "    y_real : numpy array de forma (m, 1)\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    dw : numpy array de forma (n, 1) - gradiente respecto a w\n",
    "    db : float - gradiente respecto a b\n",
    "    '''\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    # Error de predicción\n",
    "    error = y_pred - y_real.reshape(-1, 1)\n",
    "    \n",
    "    # Gradientes\n",
    "    dw = (2 / m) * X.T @ error\n",
    "    db = (2 / m) * np.sum(error)\n",
    "    \n",
    "    return dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c369898f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de w: (8, 1)\n",
      "Forma de dw: (8, 1)\n",
      "Gradiente db: -4.143893874757745\n"
     ]
    }
   ],
   "source": [
    "dw, db = calcular_gradientes(X_train_scaled, y_pred, y_train)\n",
    "\n",
    "print(\"Forma de w:\", w.shape)\n",
    "print(\"Forma de dw:\", dw.shape)\n",
    "print(\"Gradiente db:\", db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0988c0",
   "metadata": {},
   "source": [
    "## Actualización de parámetros\n",
    "\n",
    "En esta sección se implementa la regla de actualización de los pesos y el sesgo\n",
    "mediante descenso del gradiente, con el objetivo de reducir la función de pérdida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0f081d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actualizar_parametros(w, b, dw, db, learning_rate):\n",
    "    '''\n",
    "    Actualiza los pesos y el sesgo usando gradiente descendente.\n",
    "    \n",
    "    w_nuevo = w - learning_rate * dw\n",
    "    b_nuevo = b - learning_rate * db\n",
    "    '''\n",
    "    w = w - learning_rate * dw\n",
    "    b = b - learning_rate * db\n",
    "    \n",
    "    return w, b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd76a30",
   "metadata": {},
   "source": [
    "### Una iteración del descenso del gradiente\n",
    "\n",
    "A continuación se ejecuta una iteración completa del algoritmo de aprendizaje:\n",
    "propagación hacia adelante, cálculo de la pérdida, cálculo de gradientes y\n",
    "actualización de los parámetros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "afb1b640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pérdida antes: 92964.52718416127\n",
      "Pérdida después: 90167.58732431363\n"
     ]
    }
   ],
   "source": [
    "# Pérdida antes de la actualización\n",
    "y_pred = propagacion_adelante(X_train_scaled, w, b)\n",
    "loss_before = calcular_perdida(y_pred, y_train)\n",
    "\n",
    "# Cálculo de gradientes\n",
    "dw, db = calcular_gradientes(X_train_scaled, y_pred, y_train)\n",
    "\n",
    "# Actualización de parámetros\n",
    "learning_rate = 0.01\n",
    "w, b = actualizar_parametros(w, b, dw, db, learning_rate)\n",
    "\n",
    "# Pérdida después de la actualización\n",
    "y_pred_new = propagacion_adelante(X_train_scaled, w, b)\n",
    "loss_after = calcular_perdida(y_pred_new, y_train)\n",
    "\n",
    "print(\"Pérdida antes:\", loss_before)\n",
    "print(\"Pérdida después:\", loss_after)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
